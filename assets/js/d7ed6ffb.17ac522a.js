"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[59875],{32183:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>d});var o=a(24246),t=a(71670);const i={sidebar_position:70,title:"Podman AI Lab",description:"Podman AI Lab is an open source extension for Podman Desktop to work with LLMs.",keywords:["podman desktop","podman","containers","ai","llm","generative ai"],tags:["ai","llm","generative ai"]},s="Run LLMs locally",r={id:"ai-lab/index",title:"Podman AI Lab",description:"Podman AI Lab is an open source extension for Podman Desktop to work with LLMs.",source:"@site/docs/ai-lab/index.md",sourceDirName:"ai-lab",slug:"/ai-lab/",permalink:"/docs/ai-lab/",draft:!1,unlisted:!1,editUrl:"https://github.com/containers/podman-desktop/tree/main/website/docs/ai-lab/index.md",tags:[{inline:!0,label:"ai",permalink:"/docs/tags/ai"},{inline:!0,label:"llm",permalink:"/docs/tags/llm"},{inline:!0,label:"generative ai",permalink:"/docs/tags/generative-ai"}],version:"current",sidebarPosition:70,frontMatter:{sidebar_position:70,title:"Podman AI Lab",description:"Podman AI Lab is an open source extension for Podman Desktop to work with LLMs.",keywords:["podman desktop","podman","containers","ai","llm","generative ai"],tags:["ai","llm","generative ai"]},sidebar:"mySidebar",previous:{title:"Push an image to Minikube",permalink:"/docs/kubernetes/minikube/pushing-an-image-to-minikube"},next:{title:"Installing Podman AI Lab",permalink:"/docs/ai-lab/installing"}},l={},d=[{value:"Procedure",id:"procedure",level:4},{value:"Next steps",id:"next-steps",level:4}];function c(e){const n={a:"a",code:"code",h1:"h1",h4:"h4",li:"li",ol:"ol",p:"p",...(0,t.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"run-llms-locally",children:"Run LLMs locally"}),"\n",(0,o.jsx)(n.p,{children:"Podman AI Lab is the easiest way to work with Large Language Models (LLMs) on your local developer workstation. Find a catalog of recipes, leverage a curated list of open source models, experiment and compare the models. Get ahead of the curve and take your development to new heights wth Podman AI Lab!\nThere are many ways to run models locally. This extension fits perfectly into your local container workflow and exposes LLMs through inference APIs that you can directly access from your application containers. Beyond that you can use playgrounds to optimze your inference parameters and recipes that help you with ready made examples."}),"\n",(0,o.jsx)(n.h4,{id:"procedure",children:"Procedure"}),"\n",(0,o.jsx)(n.p,{children:"First thing you need to do is to install the extension itself:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.a,{href:"/docs/ai-lab/installing",children:["Install the ",(0,o.jsx)(n.code,{children:"Podman AI Lab"})," extension"]}),"."]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"next-steps",children:"Next steps"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/ai-lab/download-model",children:"Download a model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/ai-lab/start-inference-server",children:"Start an inference server for a model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/ai-lab/create-playground",children:"Creating a playground to interact with a model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/ai-lab/start-recipe",children:"Start a recipe"}),"."]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},71670:(e,n,a)=>{a.d(n,{Z:()=>r,a:()=>s});var o=a(27378);const t={},i=o.createContext(t);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);